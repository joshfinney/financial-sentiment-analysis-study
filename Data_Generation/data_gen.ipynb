{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "import chardet\n",
    "\n",
    "# Import NLTK components\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Configure pandas to display the full width of text columns\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_url(url):\n",
    "    \"\"\"\n",
    "    Extract the base domain from a given URL, removing 'www.' if it starts with it.\n",
    "    \"\"\"\n",
    "    # Check if the input is a string to ensure it's a valid URL\n",
    "    if isinstance(url, str):\n",
    "        parsed_url = urlparse(url)  # Parse the URL to separate components\n",
    "        base_url = parsed_url.netloc  # Extract the network location part (base domain)\n",
    "\n",
    "        # Remove 'www.' if the base_url starts with it\n",
    "        if base_url.startswith('www.'):\n",
    "            base_url = base_url[4:]\n",
    "\n",
    "        return base_url\n",
    "    else:\n",
    "        # Return None if input is not a string (invalid URL)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define patterns for cleaning text\n",
    "username_pattern = r'@[A-Za-z0-9_]+'\n",
    "url_pattern = r'https?://[^\\s]+'\n",
    "special_chars_and_numbers_pattern = r'[^a-zA-Z\\s]'  # Keep only letters and spaces\n",
    "combined_cleaning_pattern = r'|'.join((username_pattern, url_pattern, special_chars_and_numbers_pattern))\n",
    "\n",
    "# Extended and financial-context-specific stopwords\n",
    "custom_stopwords = {'rt', 'ep', 'gt', 'lt', 'amp'}\n",
    "extended_stopwords = set(stopwords.words('english')) | custom_stopwords\n",
    "\n",
    "# Initialize Porter Stemmer for word stemming\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text_column):\n",
    "    \"\"\"\n",
    "    Function to clean and preprocess a list of text entries, tailored for financial sentiment analysis.\n",
    "    \"\"\"\n",
    "    cleaned_texts = []\n",
    "    \n",
    "    for text in text_column:\n",
    "        # Remove usernames, URLs, and non-alphabetical characters\n",
    "        text = re.sub(combined_cleaning_pattern, ' ', text)\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Tokenize text\n",
    "        words = word_tokenize(text)\n",
    "        # Stem and remove stopwords\n",
    "        cleaned_words = [stemmer.stem(word) for word in words if word not in extended_stopwords]\n",
    "        # Rejoin words into the cleaned text\n",
    "        cleaned_text = ' '.join(cleaned_words)\n",
    "        cleaned_texts.append(cleaned_text)\n",
    "    \n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable definitions\n",
    "\n",
    "- **DS1**: Financial Tweets\n",
    "    - https://www.kaggle.com/datasets/davidwallach/financial-tweets\n",
    "- **DS2**: Financial Phrasebank\n",
    "    - https://www.kaggle.com/datasets/ankurzing/sentiment-analysis-for-financial-news\n",
    "- **DS3**: Financial Sentiment Analysis\n",
    "    - https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis\n",
    "    - FiQA and Financial Phrasebank combined\n",
    "- **DS4**: Stock Tweets\n",
    "    - Surge AI\n",
    "- **DS5**: Cryptocurrency Reddit Commetns\n",
    "    - Surge AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and labels for dataset DS1\n",
    "data_ds1 = pd.read_csv('../Datasets/DS1/Data.csv', encoding='utf-8')\n",
    "labels_ds1 = pd.read_csv('../Datasets/DS1/Labels.csv', encoding='utf-8')\n",
    "\n",
    "# Combine data and labels into a single DataFrame for DS1\n",
    "data_ds1 = pd.concat([data_ds1, labels_ds1['sentiment']], axis=1)\n",
    "\n",
    "# Detect the encoding of the dataset to handle text data properly.\n",
    "with open('../Datasets/DS2/Data.csv', 'rb') as file:\n",
    "    encoding_detection = chardet.detect(file.read(10000))\n",
    "\n",
    "# Load datasets from DS2, DS3, DS4, and DS5 with detected and default encodings\n",
    "data_ds2 = pd.read_csv('../Datasets/DS2/Data.csv', encoding=encoding_detection['encoding'])\n",
    "data_ds3 = pd.read_csv('../Datasets/DS3/Data.csv', encoding='utf-8')\n",
    "data_ds4 = pd.read_csv('../Datasets/DS4/Data.csv', encoding='utf-8')\n",
    "data_ds5 = pd.read_csv('../Datasets/DS5/Data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== DS1 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28440 entries, 0 to 28439\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             28440 non-null  object\n",
      " 1   text           28440 non-null  object\n",
      " 2   timestamp      28438 non-null  object\n",
      " 3   source         28437 non-null  object\n",
      " 4   symbols        28437 non-null  object\n",
      " 5   company_names  28435 non-null  object\n",
      " 6   url            22049 non-null  object\n",
      " 7   verified       28436 non-null  object\n",
      " 8   sentiment      28440 non-null  int64 \n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "\n",
      "===================== DS2 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4845 entries, 0 to 4844\n",
      "Data columns (total 2 columns):\n",
      " #   Column                                                                                                                           Non-Null Count  Dtype \n",
      "---  ------                                                                                                                           --------------  ----- \n",
      " 0   neutral                                                                                                                          4845 non-null   object\n",
      " 1   According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .  4845 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 75.8+ KB\n",
      "None\n",
      "\n",
      "===================== DS3 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5842 entries, 0 to 5841\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentence   5842 non-null   object\n",
      " 1   Sentiment  5842 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 91.4+ KB\n",
      "None\n",
      "\n",
      "===================== DS4 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Stock Ticker  500 non-null    object\n",
      " 1   Tweet Text    500 non-null    object\n",
      " 2   Sentiment     500 non-null    object\n",
      " 3   Tweet URL     500 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 15.8+ KB\n",
      "None\n",
      "\n",
      "===================== DS5 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 562 entries, 0 to 561\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Comment Text  562 non-null    object\n",
      " 1   Sentiment     562 non-null    object\n",
      " 2   URL           562 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 13.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"===================== DS1 Info =====================\")\n",
    "print(data_ds1.info())\n",
    "\n",
    "print(\"\\n===================== DS2 Info =====================\")\n",
    "print(data_ds2.info())\n",
    "\n",
    "print(\"\\n===================== DS3 Info =====================\")\n",
    "print(data_ds3.info())\n",
    "\n",
    "print(\"\\n===================== DS4 Info =====================\")\n",
    "print(data_ds4.info())\n",
    "\n",
    "print(\"\\n===================== DS5 Info =====================\")\n",
    "print(data_ds5.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names for DS3, DS2, and set initial mappings for DS3 and DS2\n",
    "standard_column_names = ['text', 'sentiment']\n",
    "data_ds3.columns = standard_column_names\n",
    "data_ds2.columns = ['sentiment', 'text']  # Original order in DS2\n",
    "data_ds2 = data_ds2.reindex(columns=standard_column_names)\n",
    "data_ds4.rename(columns={'Sentiment': 'sentiment'}, inplace=True)\n",
    "data_ds5.rename(columns={'Sentiment': 'sentiment'}, inplace=True)\n",
    "data_ds4.rename(columns={'Tweet Text': 'text'}, inplace=True)\n",
    "data_ds4.rename(columns={'Tweet URL': 'url'}, inplace=True)\n",
    "data_ds5.rename(columns={'Comment Text': 'text'}, inplace=True)\n",
    "data_ds5.rename(columns={'URL': 'url'}, inplace=True)\n",
    "\n",
    "# Map sentiment labels to numerical values for DS2, DS3, DS4, DS5\n",
    "sentiment_mapping = {'positive': 1, 'negative': -1, 'neutral': 0, 'Positive': 1, 'Negative': -1, 'Neutral': 0}\n",
    "data_ds2['sentiment'] = data_ds2['sentiment'].map(sentiment_mapping).astype('int64')\n",
    "data_ds3['sentiment'] = data_ds3['sentiment'].map(sentiment_mapping).astype('int64')\n",
    "data_ds4['sentiment'] = data_ds4['sentiment'].map(sentiment_mapping).astype('int64')\n",
    "data_ds5['sentiment'] = data_ds5['sentiment'].map(sentiment_mapping).astype('int64')\n",
    "\n",
    "# Remove rows from data_ds3 that are present in data_ds2\n",
    "updated_ds3 = pd.merge(data_ds3, data_ds2, on=['text', 'sentiment'], how='outer', indicator=True)\n",
    "updated_ds3 = updated_ds3[updated_ds3['_merge'] == 'left_only']\n",
    "updated_ds3.drop(columns=['_merge'], inplace=True)\n",
    "data_ds3 = updated_ds3\n",
    "\n",
    "# Drop rows with missing values in all datasets\n",
    "data_ds1.dropna(how='any', inplace=True)\n",
    "data_ds2.dropna(how='any', inplace=True)\n",
    "data_ds3.dropna(how='any', inplace=True)\n",
    "data_ds4.dropna(how='any', inplace=True)\n",
    "data_ds5.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== DS1 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22048 entries, 0 to 28439\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             22048 non-null  object\n",
      " 1   text           22048 non-null  object\n",
      " 2   timestamp      22048 non-null  object\n",
      " 3   source         22048 non-null  object\n",
      " 4   symbols        22048 non-null  object\n",
      " 5   company_names  22048 non-null  object\n",
      " 6   url            22048 non-null  object\n",
      " 7   verified       22048 non-null  object\n",
      " 8   sentiment      22048 non-null  int64 \n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 1.7+ MB\n",
      "None\n",
      "\n",
      "===================== DS2 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4845 entries, 0 to 4844\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       4845 non-null   object\n",
      " 1   sentiment  4845 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 75.8+ KB\n",
      "None\n",
      "\n",
      "===================== DS3 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1728 entries, 1 to 5852\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       1728 non-null   object\n",
      " 1   sentiment  1728 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 40.5+ KB\n",
      "None\n",
      "\n",
      "===================== DS4 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Stock Ticker  500 non-null    object\n",
      " 1   text          500 non-null    object\n",
      " 2   sentiment     500 non-null    int64 \n",
      " 3   url           500 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 15.8+ KB\n",
      "None\n",
      "\n",
      "===================== DS5 Info =====================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 562 entries, 0 to 561\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       562 non-null    object\n",
      " 1   sentiment  562 non-null    int64 \n",
      " 2   url        562 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 13.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"===================== DS1 Info =====================\")\n",
    "print(data_ds1.info())\n",
    "\n",
    "print(\"\\n===================== DS2 Info =====================\")\n",
    "print(data_ds2.info())\n",
    "\n",
    "print(\"\\n===================== DS3 Info =====================\")\n",
    "print(data_ds3.info())\n",
    "\n",
    "print(\"\\n===================== DS4 Info =====================\")\n",
    "print(data_ds4.info())\n",
    "\n",
    "print(\"\\n===================== DS5 Info =====================\")\n",
    "print(data_ds5.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Formation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Data Cleaning and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates (before cleaning):  1215\n",
      "\n",
      "Number of NAs: \n",
      " text         0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = ['text', 'sentiment']\n",
    "\n",
    "# Correct the approach to drop columns without using inplace=True\n",
    "data_ds1_full = data_ds1.drop(data_ds1.columns.difference(columns_to_keep), axis=1)\n",
    "data_ds4_full = data_ds4.drop(data_ds4.columns.difference(columns_to_keep), axis=1)\n",
    "data_ds5_full = data_ds5.drop(data_ds5.columns.difference(columns_to_keep), axis=1)\n",
    "\n",
    "# Combine all datasets into a single DataFrame\n",
    "combined_data_full = pd.concat([data_ds1_full, data_ds2, data_ds3, data_ds4_full, data_ds5_full], ignore_index=True)\n",
    "\n",
    "print(\"Number of duplicates (before cleaning): \", str(combined_data_full.duplicated('text').sum()))\n",
    "combined_data_full.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "combined_data_full['text'] = clean_text(combined_data_full['text'])\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_full.isna().sum()))\n",
    "combined_data_full.dropna(inplace=True)\n",
    "\n",
    "combined_data_full.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28468 entries, 0 to 28467\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       28468 non-null  object\n",
      " 1   sentiment  28468 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 444.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10459</th>\n",
       "      <td>kimberli clark kmb rate reiter jefferi financi group</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9259</th>\n",
       "      <td>trq turquois hill resourc million gain trq made notabl gain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>critic review gentex gntx versu delphi technolog dlph</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>zack brokerag anticip kellogg k post quarterli sale billion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>analyst expect jacob engin group inc jec announc quarterli sale billion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "10459                     kimberli clark kmb rate reiter jefferi financi group   \n",
       "9259               trq turquois hill resourc million gain trq made notabl gain   \n",
       "219                      critic review gentex gntx versu delphi technolog dlph   \n",
       "14037              zack brokerag anticip kellogg k post quarterli sale billion   \n",
       "3021   analyst expect jacob engin group inc jec announc quarterli sale billion   \n",
       "\n",
       "       sentiment  \n",
       "10459          0  \n",
       "9259           1  \n",
       "219           -1  \n",
       "14037          0  \n",
       "3021           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of NAs: \n",
      " text         0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicates (after cleaning):  4349\n"
     ]
    }
   ],
   "source": [
    "print(combined_data_full.info())\n",
    "\n",
    "display(combined_data_full.sample(5))\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_full.isna().sum()))\n",
    "\n",
    "print(\"\\nNumber of duplicates (after cleaning): \", str(combined_data_full.duplicated('text').sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data_full.to_feather('../Data/Full_Data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of 'text' duplicates (before cleaning):  693\n",
      "Number of NAs: \n",
      " text         0\n",
      "sentiment    0\n",
      "base_url     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = ['text', 'sentiment', 'url']\n",
    "\n",
    "# Correct the approach to drop columns without using inplace=True\n",
    "data_ds1_145 = data_ds1.drop(data_ds1.columns.difference(columns_to_keep), axis=1)\n",
    "data_ds4_145 = data_ds4.drop(data_ds4.columns.difference(columns_to_keep), axis=1)\n",
    "data_ds5_145 = data_ds5.drop(data_ds5.columns.difference(columns_to_keep), axis=1)\n",
    "\n",
    "# Combine all datasets into a single DataFrame\n",
    "combined_data_145 = pd.concat([data_ds1_145, data_ds4_145, data_ds5_145], ignore_index=True)\n",
    "\n",
    "print(\"\\nNumber of 'text' duplicates (before cleaning): \", str(combined_data_145.duplicated('text').sum()))\n",
    "combined_data_145.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "combined_data_145['text'] = clean_text(combined_data_145['text'])\n",
    "\n",
    "combined_data_145['base_url'] = combined_data_145['url'].apply(get_base_url)\n",
    "combined_data_145 = combined_data_145.dropna(subset=['base_url'])\n",
    "combined_data_145.drop(inplace=True, columns=['url'], axis=1)\n",
    "\n",
    "print(\"Number of NAs: \\n\", str(combined_data_145.isna().sum()))\n",
    "combined_data_145.dropna(how='any', inplace=True)\n",
    "\n",
    "combined_data_145.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22417 entries, 0 to 22416\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       22417 non-null  object\n",
      " 1   sentiment  22417 non-null  int64 \n",
      " 2   base_url   22417 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 525.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>base_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11172</th>\n",
       "      <td>citigroup increas tractor suppli tsco price target</td>\n",
       "      <td>0</td>\n",
       "      <td>thelincolnianonline.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12108</th>\n",
       "      <td>bullish big mac bullish occur pm jul semiconductor corp want ea</td>\n",
       "      <td>0</td>\n",
       "      <td>twitter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>bullish chart format exxon mobil corpor xom form bullish wedg chart pattern</td>\n",
       "      <td>0</td>\n",
       "      <td>whatsonthorold.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>signal sign market maker send move stock articl bdr</td>\n",
       "      <td>0</td>\n",
       "      <td>falconstocks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>billion sale expect zimmer biomet hold inc zbh quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>zpr.io</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              text  \\\n",
       "11172                           citigroup increas tractor suppli tsco price target   \n",
       "12108              bullish big mac bullish occur pm jul semiconductor corp want ea   \n",
       "17333  bullish chart format exxon mobil corpor xom form bullish wedg chart pattern   \n",
       "8467                           signal sign market maker send move stock articl bdr   \n",
       "2148                        billion sale expect zimmer biomet hold inc zbh quarter   \n",
       "\n",
       "       sentiment                 base_url  \n",
       "11172          0  thelincolnianonline.com  \n",
       "12108          0              twitter.com  \n",
       "17333          0       whatsonthorold.com  \n",
       "8467           0         falconstocks.com  \n",
       "2148           0                   zpr.io  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of NAs: \n",
      " text         0\n",
      "sentiment    0\n",
      "base_url     0\n",
      "dtype: int64\n",
      "\n",
      "Number of 'text' duplicates (after cleaning): 4157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       " 0    13025\n",
       " 1     6930\n",
       "-1     2462\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(combined_data_145.info())\n",
    "\n",
    "display(combined_data_145.sample(5))\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_145.isna().sum()))\n",
    "\n",
    "print(\"\\nNumber of 'text' duplicates (after cleaning): \" + str(combined_data_145.duplicated('text').sum()))\n",
    "\n",
    "display(combined_data_145['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data_145.to_feather('../Data/Data145.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'text' duplicates:  683\n",
      "\n",
      "Number of NAs: \n",
      " text             0\n",
      "company_names    0\n",
      "sentiment        0\n",
      "base_url         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['text', 'sentiment', 'company_names', 'url']\n",
    "\n",
    "# Drop all columns except 'text' and 'sentiment'\n",
    "data_ds1_1 = data_ds1.drop(data_ds1.columns.difference(columns_to_keep), axis=1)\n",
    "\n",
    "print(\"Number of 'text' duplicates: \", str(data_ds1_1.duplicated('text').sum()))\n",
    "data_ds1_1.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "data_ds1_1['text'] = clean_text(data_ds1_1['text'])\n",
    "data_ds1_1['company_names'] = clean_text(data_ds1_1['company_names'])\n",
    "\n",
    "data_ds1_1['base_url'] = data_ds1_1['url'].apply(get_base_url)\n",
    "\n",
    "data_ds1_1 = data_ds1_1.dropna(subset=['base_url'])\n",
    "data_ds1_1 = data_ds1_1.drop(columns=['url'], axis=1)\n",
    "\n",
    "combined_data_1 = data_ds1_1\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_1.isna().sum()))\n",
    "combined_data_1.dropna(how='any', inplace=True)\n",
    "\n",
    "combined_data_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21365 entries, 0 to 21364\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   text           21365 non-null  object\n",
      " 1   company_names  21365 non-null  object\n",
      " 2   sentiment      21365 non-null  int64 \n",
      " 3   base_url       21365 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 667.8+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>company_names</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>base_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>best day year today trade thx option trade ggal tsla mnkd psmt</td>\n",
       "      <td>marathon petroleum corpor</td>\n",
       "      <td>1</td>\n",
       "      <td>optionsbypros.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>black sheep china loopr walton bytom bytom sinc decemb l via</td>\n",
       "      <td>loew corpor</td>\n",
       "      <td>0</td>\n",
       "      <td>youtu.be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11713</th>\n",
       "      <td>bullish unusu option activ detect wynn</td>\n",
       "      <td>wynn resort</td>\n",
       "      <td>0</td>\n",
       "      <td>optionsonar.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20406</th>\n",
       "      <td>yet compar behemoth yore aapl peak market share mere market domin</td>\n",
       "      <td>gener motor compani</td>\n",
       "      <td>1</td>\n",
       "      <td>twitter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>aep american electr power compani inc nyse aep price target rais morgan stanley stock</td>\n",
       "      <td>american electr power compani</td>\n",
       "      <td>0</td>\n",
       "      <td>marketexclusive.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        text  \\\n",
       "3706                          best day year today trade thx option trade ggal tsla mnkd psmt   \n",
       "3499                            black sheep china loopr walton bytom bytom sinc decemb l via   \n",
       "11713                                                 bullish unusu option activ detect wynn   \n",
       "20406                      yet compar behemoth yore aapl peak market share mere market domin   \n",
       "8934   aep american electr power compani inc nyse aep price target rais morgan stanley stock   \n",
       "\n",
       "                       company_names  sentiment             base_url  \n",
       "3706       marathon petroleum corpor          1    optionsbypros.com  \n",
       "3499                     loew corpor          0             youtu.be  \n",
       "11713                    wynn resort          0      optionsonar.com  \n",
       "20406            gener motor compani          1          twitter.com  \n",
       "8934   american electr power compani          0  marketexclusive.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of NAs: \n",
      " text             0\n",
      "company_names    0\n",
      "sentiment        0\n",
      "base_url         0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicates (after cleaning): 4149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       " 0    13025\n",
       " 1     6307\n",
       "-1     2033\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(combined_data_1.info())\n",
    "\n",
    "display(combined_data_1.sample(5))\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_1.isna().sum()))\n",
    "\n",
    "print(\"\\nNumber of duplicates (after cleaning): \" + str(combined_data_1.duplicated('text').sum()))\n",
    "\n",
    "display(combined_data_1['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data_1.to_feather('../Data/Data1.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Data Cleaning and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates:  1215\n",
      "\n",
      "Number of NAs: \n",
      " text         0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = ['text', 'sentiment']\n",
    "\n",
    "# Correct the approach to drop columns without using inplace=True\n",
    "data_ds1_full = data_ds1.drop(data_ds1.columns.difference(columns_to_keep), axis=1)\n",
    "data_ds4_full = data_ds4.drop(data_ds4.columns.difference(columns_to_keep), axis=1)\n",
    "data_ds5_full = data_ds5.drop(data_ds5.columns.difference(columns_to_keep), axis=1)\n",
    "\n",
    "# Combine all datasets into a single DataFrame\n",
    "combined_data_full = pd.concat([data_ds1_full, data_ds2, data_ds3, data_ds4_full, data_ds5_full], ignore_index=True)\n",
    "\n",
    "print(\"Number of duplicates: \", str(combined_data_full.duplicated('text').sum()))\n",
    "combined_data_full.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_full.isna().sum()))\n",
    "combined_data_full.dropna(inplace=True)\n",
    "\n",
    "combined_data_full.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28468 entries, 0 to 28467\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       28468 non-null  object\n",
      " 1   sentiment  28468 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 444.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16409</th>\n",
       "      <td>REPORT: MGM Resorts sues 1000 victims of Las Vegas shooting in effort to avoid #liability $MGM https://t.co/ROItGf3gi3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>Credit Suisse Reaffirms O'Reilly Automotive $ORLY As a Neutral; They Now Have a Price Target Of $274 - https://t.co/0cZJaP5m8B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15735</th>\n",
       "      <td>RT @evanalsop4864: Huge coin selection low fees and very reliable! Join Binance! 🙌  Register for BONUS ➡️ https://t.co/sYjWfR1e8D  $ARD…</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16127</th>\n",
       "      <td>Gold prices drop on Jerome Powell testimony. https://t.co/7sMrL9j8Wy via @YouTube  $cl $es $nq $SVXY $HD $bac $AAPL… https://t.co/7Z47oj60Dk</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>It Seems Robert Half International Inc $RHI Will Go Up. Just Reported Less Shorted Shares https://t.co/MqZi2Nu5kS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               text  \\\n",
       "16409                        REPORT: MGM Resorts sues 1000 victims of Las Vegas shooting in effort to avoid #liability $MGM https://t.co/ROItGf3gi3   \n",
       "9231                 Credit Suisse Reaffirms O'Reilly Automotive $ORLY As a Neutral; They Now Have a Price Target Of $274 - https://t.co/0cZJaP5m8B   \n",
       "15735      RT @evanalsop4864: Huge coin selection low fees and very reliable! Join Binance! 🙌  Register for BONUS ➡️ https://t.co/sYjWfR1e8D  $ARD…   \n",
       "16127  Gold prices drop on Jerome Powell testimony. https://t.co/7sMrL9j8Wy via @YouTube  $cl $es $nq $SVXY $HD $bac $AAPL… https://t.co/7Z47oj60Dk   \n",
       "1968                              It Seems Robert Half International Inc $RHI Will Go Up. Just Reported Less Shorted Shares https://t.co/MqZi2Nu5kS   \n",
       "\n",
       "       sentiment  \n",
       "16409         -1  \n",
       "9231           1  \n",
       "15735          1  \n",
       "16127         -1  \n",
       "1968           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of NAs: \n",
      " text         0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicates:  0\n"
     ]
    }
   ],
   "source": [
    "print(combined_data_full.info())\n",
    "\n",
    "display(combined_data_full.sample(5))\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_full.isna().sum()))\n",
    "\n",
    "print(\"\\nNumber of duplicates: \", str(combined_data_full.duplicated('text').sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data_full.to_feather('../Data/Full_Data_NoClean.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of 'text' duplicates:  693\n",
      "\n",
      "Number of NAs: \n",
      " text         0\n",
      "sentiment    0\n",
      "base_url     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = ['text', 'sentiment', 'url']\n",
    "\n",
    "# Correct the approach to drop columns without using inplace=True\n",
    "data_ds1_145 = data_ds1.drop(data_ds1.columns.difference(columns_to_keep), axis=1)\n",
    "data_ds4_145 = data_ds4.drop(data_ds4.columns.difference(columns_to_keep), axis=1)\n",
    "data_ds5_145 = data_ds5.drop(data_ds5.columns.difference(columns_to_keep), axis=1)\n",
    "\n",
    "# Combine all datasets into a single DataFrame\n",
    "combined_data_145 = pd.concat([data_ds1_145, data_ds4_145, data_ds5_145], ignore_index=True)\n",
    "\n",
    "print(\"\\nNumber of 'text' duplicates: \", str(combined_data_145.duplicated('text').sum()))\n",
    "combined_data_145.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "combined_data_145['base_url'] = combined_data_145['url'].apply(get_base_url)\n",
    "combined_data_145 = combined_data_145.dropna(subset=['base_url'])\n",
    "combined_data_145.drop(inplace=True, columns=['url'], axis=1)\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_145.isna().sum()))\n",
    "combined_data_145.dropna(how='any', inplace=True)\n",
    "\n",
    "combined_data_145.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22417 entries, 0 to 22416\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       22417 non-null  object\n",
      " 1   sentiment  22417 non-null  int64 \n",
      " 2   base_url   22417 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 525.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>base_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11018</th>\n",
       "      <td>NTT Docomo $DCM &amp;amp; Motorola Solutions $MSI Head-To-Head Comparison https://t.co/iN7PfrLUpB</td>\n",
       "      <td>0</td>\n",
       "      <td>weekherald.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>Assurant Inc. Declares Quarterly Dividend of $0.56 $AIZ https://t.co/O8DoMU1cdi</td>\n",
       "      <td>0</td>\n",
       "      <td>zpr.io</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>$MMM $AFL $ABBV $ABT $APD $AOS $ADM $T $ADP $BDX $CAH $CVX $CINF $CTAS $CLX $KO $CL $ED $DOV $ECL $EMR $XOM $FRT https://t.co/QC3M6nFHeW</td>\n",
       "      <td>0</td>\n",
       "      <td>seekingalpha.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17988</th>\n",
       "      <td>Pfizer responded appropriately to the White House call.\" https://t.co/Frn2lezk7n $PFE</td>\n",
       "      <td>0</td>\n",
       "      <td>zerohedge.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19601</th>\n",
       "      <td>Free chrome extension to hide tweets that over-shill crypto cash tags &amp;amp; promote groups https://t.co/D6aOXBWQQj  No… https://t.co/GDB5dJ4aXe</td>\n",
       "      <td>1</td>\n",
       "      <td>shillkill.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  text  \\\n",
       "11018                                                    NTT Docomo $DCM &amp; Motorola Solutions $MSI Head-To-Head Comparison https://t.co/iN7PfrLUpB   \n",
       "5355                                                                   Assurant Inc. Declares Quarterly Dividend of $0.56 $AIZ https://t.co/O8DoMU1cdi   \n",
       "2874          $MMM $AFL $ABBV $ABT $APD $AOS $ADM $T $ADP $BDX $CAH $CVX $CINF $CTAS $CLX $KO $CL $ED $DOV $ECL $EMR $XOM $FRT https://t.co/QC3M6nFHeW   \n",
       "17988                                                            Pfizer responded appropriately to the White House call.\" https://t.co/Frn2lezk7n $PFE   \n",
       "19601  Free chrome extension to hide tweets that over-shill crypto cash tags &amp; promote groups https://t.co/D6aOXBWQQj  No… https://t.co/GDB5dJ4aXe   \n",
       "\n",
       "       sentiment          base_url  \n",
       "11018          0    weekherald.com  \n",
       "5355           0            zpr.io  \n",
       "2874           0  seekingalpha.com  \n",
       "17988          0     zerohedge.com  \n",
       "19601          1     shillkill.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of NAs: \n",
      " text         0\n",
      "sentiment    0\n",
      "base_url     0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(combined_data_145.info())\n",
    "\n",
    "display(combined_data_145.sample(5))\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_145.isna().sum()))\n",
    "\n",
    "print(\"\\nNumber of duplicates: \" + str(combined_data_145.duplicated('text').sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data_145.to_feather('../Data/Data145_NoClean.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'text' duplicates:  683\n",
      "\n",
      "Number of NAs: \n",
      " text             0\n",
      "company_names    0\n",
      "sentiment        0\n",
      "base_url         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['text', 'sentiment', 'company_names', 'url']\n",
    "\n",
    "# Drop all columns except 'text' and 'sentiment'\n",
    "data_ds1_1 = data_ds1.drop(data_ds1.columns.difference(columns_to_keep), axis=1)\n",
    "\n",
    "print(\"Number of 'text' duplicates: \", str(data_ds1_1.duplicated('text').sum()))\n",
    "data_ds1_1.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "data_ds1_1['base_url'] = data_ds1_1['url'].apply(get_base_url)\n",
    "\n",
    "data_ds1_1 = data_ds1_1.dropna(subset=['base_url'])\n",
    "data_ds1_1 = data_ds1_1.drop(columns=['url'], axis=1)\n",
    "\n",
    "combined_data_1 = data_ds1_1\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_1.isna().sum()))\n",
    "combined_data_1.dropna(how='any', inplace=True)\n",
    "\n",
    "combined_data_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21365 entries, 0 to 21364\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   text           21365 non-null  object\n",
      " 1   company_names  21365 non-null  object\n",
      " 2   sentiment      21365 non-null  int64 \n",
      " 3   base_url       21365 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 667.8+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>company_names</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>base_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11482</th>\n",
       "      <td>Mattel Sees Unusually Large Options Volume $MAT https://t.co/pUm1fO5CIM</td>\n",
       "      <td>Mattel</td>\n",
       "      <td>0</td>\n",
       "      <td>dailypolitical.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>You can trade for as low as 0.05% fee on Binance! 🤑  Register for BONUS ➡️ https://t.co/WbsCd1Jgim  $PBR $XIOS… https://t.co/KNUUkRcn9F</td>\n",
       "      <td>Transocean Ltd.</td>\n",
       "      <td>-1</td>\n",
       "      <td>binance.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>Varian Medical Systems Inc. $VAR Expected to Post Earnings of $1.00 Per Share https://t.co/c9IXOflm2G</td>\n",
       "      <td>Varian Medical Systems</td>\n",
       "      <td>1</td>\n",
       "      <td>mareainformativa.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20448</th>\n",
       "      <td>$1.01 Earnings Per Share Expected for Waste Management Inc. $WM This Quarter https://t.co/7IdDfmdqp0</td>\n",
       "      <td>Waste Management</td>\n",
       "      <td>1</td>\n",
       "      <td>ledgergazette.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3381</th>\n",
       "      <td>Insider Selling: AutoNation Inc. $AN Director Sells 42000 Shares of Stock https://t.co/GvSxegY7Pj</td>\n",
       "      <td>AutoNation</td>\n",
       "      <td>1</td>\n",
       "      <td>zpr.io</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                          text  \\\n",
       "11482                                                                  Mattel Sees Unusually Large Options Volume $MAT https://t.co/pUm1fO5CIM   \n",
       "13904  You can trade for as low as 0.05% fee on Binance! 🤑  Register for BONUS ➡️ https://t.co/WbsCd1Jgim  $PBR $XIOS… https://t.co/KNUUkRcn9F   \n",
       "741                                      Varian Medical Systems Inc. $VAR Expected to Post Earnings of $1.00 Per Share https://t.co/c9IXOflm2G   \n",
       "20448                                     $1.01 Earnings Per Share Expected for Waste Management Inc. $WM This Quarter https://t.co/7IdDfmdqp0   \n",
       "3381                                         Insider Selling: AutoNation Inc. $AN Director Sells 42000 Shares of Stock https://t.co/GvSxegY7Pj   \n",
       "\n",
       "                company_names  sentiment              base_url  \n",
       "11482                  Mattel          0    dailypolitical.com  \n",
       "13904         Transocean Ltd.         -1           binance.com  \n",
       "741    Varian Medical Systems          1  mareainformativa.com  \n",
       "20448        Waste Management          1     ledgergazette.com  \n",
       "3381               AutoNation          1                zpr.io  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of NAs: \n",
      " text             0\n",
      "company_names    0\n",
      "sentiment        0\n",
      "base_url         0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(combined_data_1.info())\n",
    "\n",
    "display(combined_data_1.sample(5))\n",
    "\n",
    "print(\"\\nNumber of NAs: \\n\", str(combined_data_1.isna().sum()))\n",
    "\n",
    "print(\"\\nNumber of duplicates: \" + str(combined_data_1.duplicated('text').sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data_1.to_feather('../Data/Data1_NoClean.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
